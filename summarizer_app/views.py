from django.shortcuts import render
import os
import re
import subprocess
import tempfile
import shutil
import time
import traceback
import math
from reportlab.lib.pagesizes import A4 
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import base64 # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã®ãŸã‚ã«è¿½åŠ 
import fitz


# pydubã¯åˆ†å‰²å‡¦ç†ã§ã¯ä¸è¦ã«ãªã£ãŸãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã¾ãŸã¯å‰Šé™¤ã‚’æ¤œè¨
# from pydub import AudioSegment 

import openai
from openai import OpenAI

from concurrent.futures import ThreadPoolExecutor, as_completed

from googleapiclient.discovery import build
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from django.conf import settings

from PIL import Image # Pillow library for image manipulation
import pytesseract # Tesseract OCR (pip install pytesseract)

# --- YouTube Data API Client Initialization ---
youtube = build('youtube', 'v3', developerKey=settings.YOUTUBE_API_KEY)

# --- OpenAI API Client Initialization ---
openai_client = None
try:
    print("OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
    openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)
    print("OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
except Exception as e:
    print(f"OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
    openai_client = None


class YoutubePaidSummarizerAPI(APIView):
    """
    API to receive a YouTube video link, transcribe its audio using OpenAI Whisper (parallelized),
    and summarize the text using OpenAI API. Also, generates practice problems.
    """

    # --- å®šæ•° ---
    CHUNK_LENGTH_SECONDS = 60 * 2 # 2åˆ† = 120ç§’ã”ã¨ã«åˆ†å‰²
    MAX_WHISPER_WORKERS = 10 # ä¸¦è¡Œã—ã¦å®Ÿè¡Œã™ã‚‹Whisper APIå‘¼ã³å‡ºã—ã®æœ€å¤§æ•°

    def post(self, request, *args, **kwargs):
        youtube_link = request.data.get('link')

        if not youtube_link:
            print("ã‚¨ãƒ©ãƒ¼: YouTubeãƒªãƒ³ã‚¯ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return Response({"error": "YouTubeãƒªãƒ³ã‚¯ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}, status=status.HTTP_400_BAD_REQUEST)

        video_id = self._extract_video_id(youtube_link)
        if not video_id:
            print(f"ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªYouTubeãƒªãƒ³ã‚¯ã§ã™ã€‚å‹•ç”»IDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {youtube_link}")
            return Response({"error": "ç„¡åŠ¹ãªYouTubeãƒªãƒ³ã‚¯ã§ã™ã€‚å‹•ç”»IDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"}, status=status.HTTP_400_BAD_REQUEST)

        temp_dir = None
        downloaded_audio_filepath = None

        try:
            temp_dir = tempfile.mkdtemp(dir=settings.MEDIA_ROOT)
            print(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {temp_dir}")

            # 1. Get video information using YouTube Data API.
            print("ã‚¹ãƒ†ãƒƒãƒ—1: YouTube Data API ã§å‹•ç”»æƒ…å ±ã®å–å¾—ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            try:
                video_response = youtube.videos().list(
                    part='snippet,contentDetails', # contentDetails ã‚’è¿½åŠ ã—ã¦å‹•ç”»ã®é•·ã•ã‚’å–å¾—
                    id=video_id
                ).execute()

                if not video_response.get('items'):
                    print(f"ã‚¨ãƒ©ãƒ¼: YouTube Data API: æŒ‡å®šã•ã‚ŒãŸIDã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_id}")
                    return Response({"error": "æŒ‡å®šã•ã‚ŒãŸIDã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}, status=status.HTTP_404_NOT_FOUND)

                video_item = video_response['items'][0]
                video_snippet = video_item['snippet']
                video_content_details = video_item['contentDetails']

                title = video_snippet.get('title', 'N/A')
                description = video_snippet.get('description', 'N/A')
                # å‹•ç”»ã®é•·ã•ã‚’å–å¾— (ISO 8601å½¢å¼ã®Durationã‚’ç§’ã«å¤‰æ›)
                duration_iso = video_content_details.get('duration')
                total_duration_seconds = self._parse_iso8601_duration(duration_iso) if duration_iso else 0

                print(f"å‹•ç”»æƒ…å ±å–å¾—å®Œäº†ã€‚ã‚¿ã‚¤ãƒˆãƒ«: {title}, é•·ã•: {total_duration_seconds}ç§’")
            except Exception as e:
                print(f"ã‚¹ãƒ†ãƒƒãƒ—1ã‚¨ãƒ©ãƒ¼: YouTube Data API ã§å‹•ç”»æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "å‹•ç”»æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # 2. Download audio from YouTube video locally using yt-dlp, directly to mp3.
            print("ã‚¹ãƒ†ãƒƒãƒ—2: yt-dlp ã§éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ (MP3å½¢å¼)ã€‚")
            try:
                downloaded_audio_extension = 'mp3'
                downloaded_audio_filename = f"{video_id}_downloaded_audio.{downloaded_audio_extension}"
                downloaded_audio_filepath = os.path.join(temp_dir, downloaded_audio_filename)

                # yt-dlpã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå“è³ªã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼ˆä»»æ„ï¼‰
                # '192K' ãªã©ã€ã‚ˆã‚Šä½ã„ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨å¤‰æ›ã‚’é«˜é€ŸåŒ–ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
                yt_dlp_command = [
                    'yt-dlp',
                    '-f', 'bestaudio',
                    '--extract-audio',
                    '--audio-format', downloaded_audio_extension,
                    # '--audio-quality', '128K', # å¿…è¦ã§ã‚ã‚Œã°è¿½åŠ 
                    '-o', downloaded_audio_filepath,
                    youtube_link,
                    '--force-overwrites'
                ]

                print(f"    yt-dlp ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ: {' '.join(yt_dlp_command)}")
                print(f"    subprocess.run å®Ÿè¡Œæ™‚ã®PATH (yt-dlp): {os.environ.get('PATH')}")
                # capture_output=False ã«ã™ã‚‹ã¨ã€yt-dlpã®é€²æ—ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã•ã‚Œã‚‹
                subprocess.run(yt_dlp_command, check=True, capture_output=False)

                if not os.path.exists(downloaded_audio_filepath) or os.path.getsize(downloaded_audio_filepath) == 0:
                    raise Exception(f"yt-dlp ãŒã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ããªã‹ã£ãŸã‹ã€ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™: {downloaded_audio_filepath}")

                print(f"éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {downloaded_audio_filepath}")
            except subprocess.CalledProcessError as e:
                error_output = e.stderr.decode('utf-8') if e.stderr else "(ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ãªã—)"
                print(f"ã‚¹ãƒ†ãƒƒãƒ—2ã‚¨ãƒ©ãƒ¼: yt-dlp ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e.cmd}")
                print(f"    ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {e.returncode}")
                print(f"    æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›:\n{error_output}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "å‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "detail": f"yt-dlp ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e.cmd}. ã‚¨ãƒ©ãƒ¼å‡ºåŠ›: {error_output}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            except FileNotFoundError as e:
                print(f"ã‚¹ãƒ†ãƒƒãƒ—2ã‚¨ãƒ©ãƒ¼: yt-dlp å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e.filename}")
                print(f"    è©³ç´°: {e.strerror}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "å‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "detail": f"yt-dlp å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e.filename}. PATHãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            except Exception as e:
                print(f"ã‚¹ãƒ†ãƒƒãƒ—2ã‚¨ãƒ©ãƒ¼: éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸMP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã«ä½¿ç”¨
            converted_audio_filepath = downloaded_audio_filepath

            # 3. Split audio into chunks and transcribe using OpenAI Whisper API in parallel.
            print("ã‚¹ãƒ†ãƒƒãƒ—3: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€OpenAI Whisper API ã§ä¸¦è¡Œã—ã¦æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            if openai_client is None:
                print("ã‚¨ãƒ©ãƒ¼: OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return Response({"error": "OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            transcript_text = ""
            try:
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆffmpegç›´æ¥å‘¼ã³å‡ºã—ï¼‰
                print(f"    éŸ³å£°ã‚’ {self.CHUNK_LENGTH_SECONDS} ç§’ã”ã¨ã«åˆ†å‰²ä¸­...")
                chunk_files = self._split_audio_ffmpeg( # _split_audio ã‹ã‚‰ _split_audio_ffmpeg ã«å¤‰æ›´
                    audio_file_path=converted_audio_filepath,
                    total_duration_seconds=total_duration_seconds, # å‹•ç”»ã®ç·æ™‚é–“ã‚’æ¸¡ã™
                    chunk_length_seconds=self.CHUNK_LENGTH_SECONDS,
                    output_dir=temp_dir
                )
                print(f"    {len(chunk_files)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")

                if not chunk_files:
                    print("è­¦å‘Š: åˆ†å‰²ã•ã‚ŒãŸéŸ³å£°ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–‡å­—èµ·ã“ã—ã§ãã¾ã›ã‚“ã€‚")
                    transcript_text = ""
                else:
                    # ä¸¦è¡Œã—ã¦æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ
                    transcription_results = [None] * len(chunk_files) # é †åºã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ

                    with ThreadPoolExecutor(max_workers=self.MAX_WHISPER_WORKERS) as executor:
                        future_to_chunk = {
                            executor.submit(self._transcribe_audio_chunk_parallel, chunk_info): chunk_info
                            for chunk_info in chunk_files
                        }

                        for future in as_completed(future_to_chunk):
                            chunk_info = future_to_chunk[future]
                            try:
                                result = future.result()
                                if "error" in result:
                                    print(f"    ãƒãƒ£ãƒ³ã‚¯ {result['index']} ã®æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result['error']}")
                                    transcription_results[result["index"]] = f"[æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {result['error']}]"
                                else:
                                    transcription_results[result["index"]] = result["text"]
                            except Exception as exc:
                                print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_info['index']} ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {exc}")
                                transcription_results[chunk_info["index"]] = f"[ä¸æ˜ãªæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {exc}]"

                    # å…¨ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã®æ–‡å­—èµ·ã“ã—çµæœã‚’çµåˆ
                    full_transcript_parts = [text for text in transcription_results if text is not None]
                    transcript_text = "\n".join(full_transcript_parts).strip()

                print("æ–‡å­—èµ·ã“ã—å®Œäº†ã€‚")

                if not transcript_text:
                    print("è­¦å‘Š: éŸ³å£°ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    return Response({
                        "title": title,
                        "description": description,
                        "transcript": "",
                        "summary": "å‹•ç”»ã®éŸ³å£°ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è¦ç´„ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚",
                        "practice_problems": "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„ãŸã‚ã€ç·´ç¿’å•é¡Œã¯ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚",
                    }, status=status.HTTP_200_OK)

            except Exception as e:
                print(f"ã‚¹ãƒ†ãƒƒãƒ—3ã‚¨ãƒ©ãƒ¼: Whisper API ã§æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # 4. Generate summary using OpenAI API.
            print("ã‚¹ãƒ†ãƒƒãƒ—4: OpenAI API ã§è¦ç´„ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            if openai_client is None:
                print("ã‚¨ãƒ©ãƒ¼: OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return Response({"error": "OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            try:
                prompt_summary = f"ã‚ãªãŸã¯æ•™æã‚’ä½œã‚‹ãƒ—ãƒ­ã®è¬›å¸«ã§ã™ã€‚ã“ã‚Œã‹ã‚‰æ¸¡ã™YouTubeå‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æ–‡å­—èµ·ã“ã—ã‚’èª­ã¿ã€è¦ç´„ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€ç‰©ç†ã‚„æ•°å­¦ã®å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ã«å•é¡Œã®è§£æ³•ã‚’ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã€å‡ºåŠ›å½¢å¼ã®ãƒ«ãƒ¼ãƒ«ã€‘1. å•é¡Œã®å†…å®¹ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚2. è§£ããŸã‚ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †ç•ªã«æ›¸ã„ã¦ãã ã•ã„ï¼ˆSTEP 1, STEP 2 ã®ã‚ˆã†ã«ï¼‰exã€‚3. ä½¿ç”¨ã™ã‚‹å…¬å¼ã‚„æ¡ä»¶ã¯ã™ã¹ã¦æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚4. æ•°å¼ã¯ LaTeX å½¢å¼ã§è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š\\( y = ax^2 + bx + c \\)ï¼‰ã€‚5.æ•°å¼ãŒå‡ºã¦ãã‚‹å ´åˆã¯ç›´å‰ã¨ç›´å¾Œã«æ”¹è¡Œã‚’è¡Œã£ã¦ãã ã•ã„ã€‚6. è§£ç­”ã«è‡³ã‚‹ã¾ã§ã®å¼å¤‰å½¢ã€ä»£å…¥ã€è¨ˆç®—æ‰‹é †ã‚’è©³ç´°ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚7. æœ€å¾Œã«ç­”ãˆã‚‚æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚\n\nå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {title}\n\næ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿:\n{transcript_text}\n\nè¦ç´„:"
                print("    OpenAI API (è¦ç´„) ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
                response_summary_openai = openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯å‹•ç”»ã®å†…å®¹ã‚’è¦ç´„ã—ã¦å‚è€ƒæ›¸ã‚’ä½œã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                        {"role": "user", "content": prompt_summary}
                    ],
                    max_tokens=1000,
                    temperature=0.7,
                )
                summary = response_summary_openai.choices[0].message.content.strip()
                print("è¦ç´„å®Œäº†ã€‚")
            except Exception as e:
                print(f"ã‚¹ãƒ†ãƒƒãƒ—4ã‚¨ãƒ©ãƒ¼: OpenAI API ã§è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # 5. Generate practice problems using OpenAI API.
            print("ã‚¹ãƒ†ãƒƒãƒ—5: OpenAI API ã§ç·´ç¿’å•é¡Œã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            practice_problems = "ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            if openai_client: # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½(â‰ None)ãªå ´åˆã®ã¿å®Ÿè¡Œ
                    # æ–‡å­—åˆ—ã®å‰ã®fã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—ã‚’ç¤ºã™ï¼ï¼ˆæ–‡å­—åˆ—ã®ä¸­ã«å¤‰æ•°ã‚’åŸ‹ã‚è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ï¼‰
                prompt_problems = (
                    f"ã‚ãªãŸã¯å„ªç§€ãªä½œå•è€…ã¨ã—ã¦ã€ä¸ãˆã‚‰ã‚ŒãŸ YouTube å‹•ç”»ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æ–‡å­—èµ·ã“ã—ã‚’èª­ã¿å–ã‚Šã€"
                    f"å‹•ç”»ãŒæ•°å­¦ãƒ»ç‰©ç†ã«é–¢ã™ã‚‹å†…å®¹ã§ã‚ã‚Œã°ã€å†…å®¹ã«åŸºã¥ã„ã¦æ—¥æœ¬èªã§ç·´ç¿’å•é¡Œã‚’5å•ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                    f"ãã®éš›ã€é€šå¸¸ã®è¨˜è¿°å¼å•é¡Œï¼ˆä¾‹ï¼šå¼ã‚’è§£ããƒ»å®šç†ã‚’èª¬æ˜ã™ã‚‹ãªã©ï¼‰ã‚’ç”¨ã„ã¦ãã ã•ã„ã€‚\n"
                    f"ä¸€æ–¹ã€å‹•ç”»ãŒæ•°å­¦ãƒ»ç‰©ç†ä»¥å¤–ã®å†…å®¹ã§ã‚ã‚Œã°ã€ãã®åˆ†é‡ã«é–¢é€£ã—ãŸ**çŸ¥è­˜ã®ç©´åŸ‹ã‚å•é¡Œ**ã‚’5å•ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                    f"ä¾‹ãˆã°ã€æ­´å²ã‚„ç¤¾ä¼šã«é–¢ã™ã‚‹å†…å®¹ã§ã‚ã‚Œã°ã€ç”¨èªã‚„äººåã€å‡ºæ¥äº‹ãªã©ã‚’ç©ºæ¬„ã«ã—ãŸæ–‡ã‚’æç¤ºã—ã€ãã‚Œã«å¯¾å¿œã™ã‚‹æ­£ç­”ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚\n"
                    f"ã¾ãš ã€Œå•é¡Œæ–‡ã®ã¿ã€ ã®ãƒ‘ãƒ¼ãƒˆã«ï¼•å•ã‚’åˆ—æŒ™ã—ã€ç¶šã ã€Œå•é¡Œã¨è§£ç­”ã€ ã®ãƒ‘ãƒ¼ãƒˆã§ã¯ã€"
                    f"å…ˆç¨‹ç”Ÿæˆã—ãŸ5å•ã¨å…¨ãåŒã˜å„å•é¡Œã®ç›´å¾Œã«å°å‡ºéç¨‹ã‚’è©³è¿°ã—ãŸè§£ç­”ã‚’ä½µè¨˜ã—ã¦æç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
                    f"æ•°å¼ãŒå¿…è¦ãªéš›ã¯ï¼Œ[+,ãƒ¼,Ã—ï¼ŒÃ·,=,â‰ ,â‰¡,âˆ,âˆ«,âˆ‘,âˆš]ãªã©ã®è¨˜å·ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n\n"
                    f"å›ç­”ã¯ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
                    f"ç”Ÿæˆã—ãŸæ•°å¼ã®å‰å¾Œã«ï¼Œãã‚Œãã‚Œæ”¹è¡Œ['\n']ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚\n\n"
                    f"(ç‰©ç†ãƒ»æ•°å­¦ã®å ´åˆã‹ã¤å•é¡Œã¨è§£ç­”ã®å ´åˆ):\n"
                    f"å•é¡Œ1:[å•é¡Œæ–‡ã‚’è¨˜è¼‰]\n"
                    f"è§£ç­”1:[å•é¡Œã®è§£ç­”ã¨å°å‡ºéç¨‹ã‚’è©³è¿°]\n"
                    f"å•é¡Œ2:[å•é¡Œæ–‡ã‚’è¨˜è¼‰]\n"
                    f"è§£ç­”2:[å•é¡Œã®è§£ç­”ã¨å°å‡ºéç¨‹ã‚’è©³è¿°]\n"
                    f"å•é¡Œ3:[å•é¡Œæ–‡ã‚’è¨˜è¼‰]\n"
                    f"è§£ç­”3:[å•é¡Œã®è§£ç­”ã¨å°å‡ºéç¨‹ã‚’è©³è¿°]\n"
                    f"å•é¡Œ4:[å•é¡Œæ–‡ã‚’è¨˜è¼‰]\n"
                    f"è§£ç­”4:[å•é¡Œã®è§£ç­”ã¨å°å‡ºéç¨‹ã‚’è©³è¿°]\n"
                    f"å•é¡Œ5:[å•é¡Œæ–‡ã‚’è¨˜è¼‰]\n"
                    f"è§£ç­”5:[å•é¡Œã®è§£ç­”ã¨å°å‡ºéç¨‹ã‚’è©³è¿°]\n\n"
                    f"(ç‰©ç†ãƒ»æ•°å­¦ä»¥å¤–ã®å ´åˆã‹ã¤å•é¡Œæ–‡ã®ã¿ã®å ´åˆ):\n"
                    f"å•é¡Œ:[ç©´åŸ‹ã‚å•é¡Œæ–‡ã‚’è¨˜è¼‰]\n\n"
                    f"è§£ç­”:[ç©´åŸ‹ã‚ã•ã‚Œã¦ã„ãªã„å…¨æ–‡ã‚’è¨˜è¼‰(ç©´åŸ‹ã‚ã«ãªã£ã¦ã„ãŸç®‡æ‰€ã«ã¯ï¼ŒåŒæ§˜ã®ä½ç½®ã«æ‹¬å¼§ã‚’ä»˜ã‘ã¦ ([ç©´åŸ‹ã‚ç®‡æ‰€ã®è§£ç­”ã‚’è¨˜è¼‰])) ]\n"
                    f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {title}\n\n"
                    f"æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿:\n{transcript_text}\n\n"
                    f"ç·´ç¿’å•é¡Œã¨è§£ç­”:"
                )             
                print("    OpenAI API (ç·´ç¿’å•é¡Œ) ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
                try:
                    response_problems_openai = openai_client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": "ã‚ãªãŸã¯å‹•ç”»å†…å®¹ã‹ã‚‰ç·´ç¿’å•é¡Œã‚’ä½œæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}, #role:systemã¯AIã«ã©ã‚“ãªå½¹å‰²ã‚’ä¸ãˆã‚‹ã‹ã‚’æŒ‡å®š
                            {"role": "user", "content": prompt_problems} #role:userã¯ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®å…¥åŠ›ã‚’ç¤ºã™
                        ],
                        max_tokens=1500, # å‡ºåŠ›ã•ã‚Œã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆæ—¥æœ¬èªã§ç´„3000å­—ï¼‰
                        temperature=0.7, # ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’åˆ¶å¾¡ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå …ã„ï¼š0.0ã€œ1.0ï¼šå‰µé€ çš„ï¼‰
                    )
                    practice_problems = response_problems_openai.choices[0].message.content.strip()
                    print("ç·´ç¿’å•é¡Œã®ç”Ÿæˆå®Œäº†ã€‚")

                    judge = self.judge_necessarily_graph(transcript_text)   # ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤æ–­

                    if judge:
                        print("ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã¨åˆ¤æ–­ã•ã‚Œã¾ã—ãŸã€‚æ•°å¼ã‚’æŠ½å‡ºã—ã¾ã™...")
                        latex_equations = self.latex_from_text(practice_problems)  # æ•°å¼ã‚’æŠ½å‡º
                        after_latex_equations = self.latex_to_python(latex_equations)  # x, y ã®ã¿ã®æ•°å¼ã‚’æŠ½å‡º
                        if after_latex_equations:
                            for i, equation in enumerate(after_latex_equations):
                                print(f"æŠ½å‡ºã•ã‚ŒãŸæ•°å¼: {equation}")
                                create_graph_filename = f"{video_id}graph_{i+1}"
                                success, graph_file_path = self.create_graph_from_latex(
                                    latex_equation=equation,
                                    filename=create_graph_filename,
                                    quality='l',
                                    k=9.8
                                )
                            
                                if success:
                                    print(f"ã‚°ãƒ©ãƒ•å‹•ç”»ã®ç”Ÿæˆã«æˆåŠŸã—ã¾ã—ãŸ: {graph_file_path}")
                                    practice_problems += f"\n\nã‚°ãƒ©ãƒ•å‹•ç”»ã¯ã“ã¡ã‚‰: {graph_file_path}"
                                else:
                                    print("ã‚°ãƒ©ãƒ•å‹•ç”»ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

                        else:
                            print("è­¦å‘Š: æ•°å¼ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚°ãƒ©ãƒ•å‹•ç”»ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã€‚")
                            practice_problems += "\n\nã‚°ãƒ©ãƒ•å‹•ç”»ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ•°å¼ãŒæŠ½å‡ºã§ããªã‹ã£ãŸãŸã‚ã§ã™ã€‚"

                except Exception as problem_e:
                    print(f"ã‚¹ãƒ†ãƒƒãƒ—5ã‚¨ãƒ©ãƒ¼: ç·´ç¿’å•é¡Œã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {problem_e}")
                    print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                    practice_problems = f"ç·´ç¿’å•é¡Œã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {problem_e}"
            else:
                print("è­¦å‘Š: OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ç·´ç¿’å•é¡Œã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã€‚")
            # 6. Return the response with title, description, transcript, summary, and practice problems.
            combined_output = f"{summary}\n\n{practice_problems}"

            return Response({
                "title": title,
                "description": description,
                "transcript": transcript_text,
                "summary": summary,
                "practice_problems": practice_problems
            }, status=status.HTTP_200_OK)

        except Exception as e:
            traceback_str = traceback.format_exc()
            print(f"APIå‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback_str}")
            return Response({"error": "å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        finally:
            if temp_dir and os.path.exists(temp_dir):
                print(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã™: {temp_dir}")
                shutil.rmtree(temp_dir)
    
    # --- ã‚°ãƒ©ãƒ•å¿…è¦æ€§åˆ¤æ–­ãƒ¡ã‚½ãƒƒãƒ‰ ---
    def judge_necessarily_graph(self, text):
        """
        æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã«ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åŠ¹ç‡çš„ã«åˆ¤æ–­ã™ã‚‹ã€‚
        ã‚°ãƒ©ãƒ•ãŒå¿…è¦ãªå ´åˆã¯Trueã€ä¸è¦ãªå ´åˆã¯Falseã‚’è¿”ã™ã€‚
        """
        # 1. ã¾ãšã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§é«˜é€Ÿãƒã‚§ãƒƒã‚¯
        keywords = ["ã‚°ãƒ©ãƒ•","è¡¨","ãƒ—ãƒ­ãƒƒãƒˆ", "å›³è¡¨", "ã‚°ãƒ©ãƒ•åŒ–", "å¯è¦–åŒ–", "ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–", "ã‚°ãƒ©ãƒ•ã‚’æã", "ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"]
        if any(keyword in text for keyword in keywords):
            print(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{next(keyword for keyword in keywords if keyword in text)}' ãŒè¦‹ã¤ã‹ã£ãŸãŸã‚ã€ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã¨åˆ¤æ–­ã—ã¾ã—ãŸã€‚")
            return True

        # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã®ã¿ã€AIã«å•ã„åˆã‚ã›ã‚‹
        if openai_client is None:
            print("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãšã€OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚‚æœªåˆæœŸåŒ–ã§ã™ã€‚ã‚°ãƒ©ãƒ•ã¯ä¸è¦ã¨åˆ¤æ–­ã—ã¾ã™ã€‚")
            return False

        print("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€AIã«ã‚ˆã‚‹åˆ¤æ–­ã‚’é–‹å§‹ã—ã¾ã™...")
        try:
            judge_from_openai_client = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã¨ã—ã¦ã€ä¸ãˆã‚‰ã‚ŒãŸæ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã«ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": f"ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã«ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã§ã™ã‹ï¼Ÿå¿…è¦ãªå ´åˆã¯ã€ŒTrueã€ã€ä¸è¦ãªå ´åˆã¯ã€ŒFalseã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚ã¾ãŸç¢ºå®Ÿã«ï¼Œã€ŒTrueã€orã€ŒFalseã€ã®ï¼’æŠã§è§£ç­”ã—ãªã•ã„ï¼ãã®ã»ã‹ã®æ–‡å­—åˆ—ã¯ä¸€åˆ‡ä¸è¦ã§ã‚ã‚‹ï¼\n\n{text}"}
                ],
                max_tokens=10, # "True"ã‹"False"ã ã‘ãªã®ã§ãƒˆãƒ¼ã‚¯ãƒ³ã¯å°‘é‡ã§è‰¯ã„
                temperature=0.0,
            )
            result_str = judge_from_openai_client.choices[0].message.content.strip()
            
            # "True"ã¨ã„ã†å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã§åˆ¤æ–­ã™ã‚‹ã€ã‚ˆã‚Šå …ç‰¢ãªæ–¹æ³•
            if "True" in result_str:
                print("AIãŒã‚°ãƒ©ãƒ•ã‚’å¿…è¦ã¨åˆ¤æ–­ã—ã¾ã—ãŸã€‚")
                return True
            else:
                print("AIãŒã‚°ãƒ©ãƒ•ä¸è¦ã¨åˆ¤æ–­ã—ã¾ã—ãŸã€‚")
                return False

        except Exception as e:
            print(f"OpenAI APIã§ã®ã‚°ãƒ©ãƒ•å¿…è¦æ€§åˆ¤æ–­ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            # APIã‚¨ãƒ©ãƒ¼æ™‚ã¯å®‰å…¨ç­–ã¨ã—ã¦Falseã‚’è¿”ã™
            return False
        
    def latex_from_text(self, text: str) -> list[str]:
        """
        ãƒ¡ã‚½ãƒƒãƒ‰ã®ç›®çš„ã¨ã—ã¦ã¯ï¼Œã‚°ãƒ©ãƒ•å‹•ç”»ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã«æ¸¡ã™ãŸã‚ã®LaTeXå½¢å¼ã®æ•°å¼ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ï¼Œjudge_necessarily_graphãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚°ãƒ©ãƒ•ãŒå¿…è¦ã¨åˆ¤æ–­ã•ã‚ŒãŸå ´åˆã«ã€ä½¿ç”¨ã™ã‚‹
        æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å¼ã‚’æŠ½å‡ºã—ã€LaTeXå½¢å¼ã§è¿”ã™ã€‚
        ã‚°ãƒ©ãƒ•ãŒå¿…è¦ãªæ•°å¼ãŒè¤‡æ•°ã‚ã£ãŸå ´åˆã¯ï¼Œãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã™ã€‚
        """
        if openai_client is None:
            print("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæœªåˆæœŸåŒ–ã®ãŸã‚ã€æ•°å¼ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã€‚")
            return []

        # GPT-4ã«æ•°å¼æŠ½å‡ºã‚’ä¾é ¼ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        extraction_prompt = f"""
        ã‚ãªãŸã¯å„ªç§€ãªæ•°å­¦è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€æ•°å¼ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„

        æ¡ä»¶:
        1. æŠ½å‡ºã—ãŸæ•°å¼ã¯ã€ãã‚Œãã‚Œåˆ¥ã®è¡Œã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        2. æ•°å¼ã¯å¿…ãšLaTeXå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹: x = \frac{1}{2} y^2 + 3yï¼‰
        3. å‡ºåŠ›ã«ã¯æ•°å¼ä»¥å¤–ä¸€åˆ‡å¿…è¦ã‚ã‚Šã¾ã›ã‚“ï¼èª¬æ˜æ–‡ã€æŒ¨æ‹¶ã€è¨˜å·ï¼ˆç®‡æ¡æ›¸ãã®ãƒã‚¤ãƒ•ãƒ³ãªã©ï¼‰ã‚’ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
        4. æ•°å¼ãŒä¸€ã¤ã‚‚è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã¯ã€å¿…ãšã€ŒNoneã€ã¨ã„ã†å˜èªã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

        å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ:
        ---
        {text}
        ---
        """
        print("AIã«ã‚ˆã‚‹æ•°å¼ã®æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™...")
        try:
            response = openai_client.chat.completions.create(
                model="gpt-4", 
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å¼ã‚’æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": extraction_prompt}
                ],
                max_tokens=500,
                temperature=0.0,
            )
            result = response.choices[0].message.content.strip()

            if result == "None" or not result:
                print("AIã¯æ•°å¼ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                return []
            
            # çµæœã‚’æ”¹è¡Œã§åˆ†å‰²ã—ã€ç©ºè¡Œã‚’é™¤å¤–ã—ã¦ãƒªã‚¹ãƒˆåŒ–
            extracted_equations = [line.strip() for line in result.split('\n') if line.strip()]
            print(f"AIãŒæŠ½å‡ºã—ãŸæ•°å¼: {extracted_equations}")
            return extracted_equations

        except Exception as e:
            print(f"OpenAI APIã§ã®æ•°å¼æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return []


# --------------------------------------------------------------------------
    # ã‚°ãƒ©ãƒ•å‹•ç”»ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ (ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚ºå¼·åŒ– æœ€çµ‚ç‰ˆ)
    # --------------------------------------------------------------------------
    def create_graph_from_latex(self, latex_equation: str, filename: str, quality: str = 'l', **variables):
        """
        LaTeXå½¢å¼ã®æ•°å¼ã‚’å…ƒã«é–¢æ•°ã®ã‚°ãƒ©ãƒ•ã‚’æç”»ã™ã‚‹Manimå‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ã€‚
        ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨æ–‡å­—åˆ—ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã‚’å¼·åŒ–ã—ãŸæœ€çµ‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚
        """
        # --- STEP 1: å¤‰æ•°ã®ç½®ãæ›ãˆã¨LaTeXæ–‡å­—åˆ—ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º ---
        processed_latex = latex_equation
        if variables:
            print(f"å¤‰æ•°ã‚’ç½®ãæ›ãˆã¾ã™: {variables}")
            for key, value in variables.items():
                processed_latex = processed_latex.replace(key, str(value))
        
        # â–¼â–¼â–¼ã€æ±ºå®šç‰ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºå‡¦ç†ã€‘â–¼â–¼â–¼
        # 1. ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ `*` ã‚’LaTeXã®ä¹—ç®—è¨˜å· `\times` ã«ç½®æ›
        processed_latex = processed_latex.replace('*', r' \times ')
        # 2. å‰å¾Œã® `\(` ã¨ `\)` ã‚’é™¤å»
        processed_latex = processed_latex.strip().replace(r"\(", "").replace(r"\)", "").strip()
        # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
        
        print(f"LaTeXå…¥åŠ› (ã‚µãƒ‹ã‚¿ã‚¤ã‚ºãƒ»å¤‰æ•°ç½®æ›å¾Œ): '{processed_latex}'")


        # --- STEP 2: LaTeXã‹ã‚‰Pythonã®æ•°å¼æ–‡å­—åˆ—ã¸ã®å¤‰æ› ---
        def latex_to_python_expr(latex_str: str) -> str:
            # ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã¯STEP1ã§å®Œäº†ã—ã¦ã„ã‚‹ãŒã€å¿µã®ãŸã‚ã“ã“ã§ã‚‚é™¤å»
            expr = latex_str.strip().replace(r"\(", "").replace(r"\)", "").strip()
            if expr.startswith('y'):
                expr = re.sub(r'y\s*=\s*', '', expr)
            expr = re.sub(r'\\sqrt\{([^}]+)\}', r'np.sqrt(\1)', expr)
            expr = re.sub(r'\\(sin|cos|tan|log|ln|exp)', r'np.\1', expr)
            expr = re.sub(r'\\frac\{([^}]+)\}\{([^}]+)\}', r'((\1)/(\2))', expr)
            expr = re.sub(r'\\pi', 'np.pi', expr)
            expr = expr.replace('{', '(').replace('}', ')')
            expr = expr.replace(r'\left(', '(').replace(r'\right)', ')')
            expr = expr.replace('^', '**')
            protected_funcs = {}
            def protect_func(match):
                key = f"##NPFUNC{len(protected_funcs)}##"
                protected_funcs[key] = match.group(0)
                return key
            expr = re.sub(r'np\.\w+', protect_func, expr)
            expr = re.sub(r'(?<=[0-9a-zA-Z\)])(?=[a-zA-Z\(])', '*', expr)
            expr = re.sub(r'(?<=\))(?=\d)', '*', expr)
            for key, value in protected_funcs.items():
                expr = expr.replace(key, value)
            return expr

        # STEP1ã§ã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ã®æ–‡å­—åˆ—ã‚’æ¸¡ã™
        python_expr = latex_to_python_expr(processed_latex)
        print(f"å¤‰æ›å¾Œã®Pythonå¼: '{python_expr}'")


        # --- STEP 3: Manimã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆ (ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥å¼·åŒ–ç‰ˆ) ---
        manim_code = f"""
import sys
from manim import *
import numpy as np

class FormulaScene(Scene):
    def construct(self):
        axes = Axes(
            x_range=[-5, 5, 1], y_range=[-5, 5, 1],
            axis_config={{"include_tip": True, "include_numbers": True}}
        )
        axes.add_coordinates()
        try:
            graph = axes.plot(lambda x: {python_expr}, color=BLUE)
            label = axes.get_graph_label(graph, label=r'''{processed_latex}''')
            self.play(Create(axes), Create(graph))
            self.play(Write(label))
        except Exception as e:
            error_message = str(e).replace('"', "'").replace("\\n", " ")
            error_text = Text(f"Error: {{error_message}}", font_size=24, color=RED)
            self.play(Write(error_text))
            sys.exit(1)
        self.wait(2)
"""

        # --- STEP 4: Manimã®å®Ÿè¡Œã¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† ---
        # (ã“ã®STEPã®Pythonã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
        with tempfile.TemporaryDirectory() as tmpdir:
            script_name = "manim_script.py"
            manim_file_path = os.path.join(tmpdir, script_name)
            with open(manim_file_path, "w", encoding="utf-8") as f:
                f.write(manim_code)
            try:
                quality_flag = f"-q{quality}"
                command = ["manim", quality_flag, manim_file_path, "FormulaScene"]
                print(f"ğŸ”„ Manimã‚’å®Ÿè¡Œä¸­... ã‚³ãƒãƒ³ãƒ‰: {' '.join(command)}")
                subprocess.run(command, cwd=tmpdir, check=True, capture_output=True, text=True)
                quality_dirs = {'l': '480p15', 'm': '720p30', 'h': '1080p60', 'k': '2160p60'}
                quality_dir = quality_dirs.get(quality, '480p15')
                source_path = os.path.join(tmpdir, "media", "videos", os.path.splitext(script_name)[0], quality_dir, "FormulaScene.mp4")
                if os.path.exists(source_path):
                    output_dir = os.path.join(settings.MEDIA_ROOT, "graphs")
                    os.makedirs(output_dir, exist_ok=True)
                    final_filename = f"{filename}.mp4"
                    final_path = os.path.join(output_dir, final_filename)
                    shutil.move(source_path, final_path)
                    print(f"âœ… ã‚°ãƒ©ãƒ•å‹•ç”»ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {final_path}")
                    final_url = os.path.join(settings.MEDIA_URL, "graphs", final_filename)
                    return True, final_url
                else:
                    print(f"âš ï¸ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {source_path}")
                    return False, None
            except subprocess.CalledProcessError as e:
                print("âŒ Manim å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                print(f"--- STDERR ---\n{e.stderr}")
                return False, None
            except FileNotFoundError:
                print("âŒ 'manim' ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Dockerã‚³ãƒ³ãƒ†ãƒŠã«ManimãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return False, None

    def latex_to_python(self, latex_equations):
        """
        LaTeXå½¢å¼ã®æ•°å¼ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€å¤‰æ•°ãŒ x, y ã®ã¿ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹æ•°å¼ã ã‘ã‚’æŠ½å‡ºã™ã‚‹ã€‚

        Args:
            latex_equations (list of str): LaTeXæ•°å¼ã®æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã€‚

        Returns:
            list of str: x, y ã®ã¿ã‚’å«ã‚€æ•°å¼ã®ãƒªã‚¹ãƒˆã€‚
        """
        allowed_vars = {'x', 'y'}
        filtered_equations = []

        for eq in latex_equations:
            # LaTeXã®æ‹¬ã‚Šï¼ˆ\( ã¨ \)ï¼‰ã‚’é™¤å»
            stripped_eq = eq.strip().replace(r"\(", "").replace(r"\)", "")
            
            # 1. LaTeXã‚³ãƒãƒ³ãƒ‰ï¼ˆ\frac, \sin ãªã©ï¼‰ã‚’å…ˆã«é™¤å»ã™ã‚‹
            eq_no_commands = re.sub(r'\\[a-zA-Z]+', ' ', stripped_eq)
            
            # 2. ã‚³ãƒãƒ³ãƒ‰é™¤å»å¾Œã®æ–‡å­—åˆ—ã‹ã‚‰è‹±å°æ–‡å­—å¤‰æ•°ã‚’æŠ½å‡ºã™ã‚‹
            variables = set(re.findall(r"[a-zA-Z]", eq_no_commands))
            # --- ã“ã“ã¾ã§ä¿®æ­£ ---

            # ä½¿ç”¨å¤‰æ•°ãŒ x, y ã®ã¿ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
            if variables.issubset(allowed_vars):
                filtered_equations.append(eq)
            else:
                print(f"é™¤å¤–: {eq}ï¼ˆå«ã¾ã‚Œã‚‹å¤‰æ•°: {variables}ï¼‰")

        return filtered_equations


    def _extract_video_id(self, youtube_link):
        """
        YouTubeãƒªãƒ³ã‚¯ã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡ºã™ã‚‹
        """
        match_v = re.search(r'(?:v=|youtu\.be\/|embed\/|v\/|watch\?v%3D|&v=|%2Fv%2F)([a-zA-Z0-9_-]{11})', youtube_link)
        if match_v:
            return match_v.group(1)

        match_short = re.search(r'youtu\.be\/([a-zA-Z0-9_-]{11})', youtube_link)
        if match_short:
            return match_short.group(1)

        match_embed = re.search(r'youtube\.com\/embed\/([a-zA-Z0-9_-]{11})', youtube_link)
        if match_embed:
            return match_embed.group(1)

        return None

    def _parse_iso8601_duration(self, duration_str):
        """
        ISO 8601å½¢å¼ã®æœŸé–“æ–‡å­—åˆ— (ä¾‹: PT1H2M3S) ã‚’ç§’æ•°ã«å¤‰æ›ã™ã‚‹
        """
        # æ­£è¦è¡¨ç¾ã§H (æ™‚é–“), M (åˆ†), S (ç§’) ã‚’æŠ½å‡º
        hours = re.search(r'(\d+)H', duration_str)
        minutes = re.search(r'(\d+)M', duration_str)
        seconds = re.search(r'(\d+)S', duration_str)

        total_seconds = 0
        if hours:
            total_seconds += int(hours.group(1)) * 3600
        if minutes:
            total_seconds += int(minutes.group(1)) * 60
        if seconds:
            total_seconds += int(seconds.group(1))

        return total_seconds

    def _split_audio_ffmpeg(self, audio_file_path, total_duration_seconds, chunk_length_seconds, output_dir):
        """
        ffmpegã‚³ãƒãƒ³ãƒ‰ã‚’ç›´æ¥ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã•ã‚ŒãŸç§’æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
        ã“ã®æ–¹æ³•ã¯pydubã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        chunks = []
        # ç·å†ç”Ÿæ™‚é–“ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨ˆç®—
        num_chunks = math.ceil(total_duration_seconds / chunk_length_seconds)

        for i in range(num_chunks):
            start_time_seconds = i * chunk_length_seconds

            # ãƒãƒ£ãƒ³ã‚¯ã®çµ‚äº†æ™‚é–“ã¯ã€æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã®é–‹å§‹æ™‚é–“ã€ã¾ãŸã¯ç·æ™‚é–“ã¾ã§
            # durationã¯ã€ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯ã®é•·ã•
            duration_current_chunk = chunk_length_seconds
            if start_time_seconds + chunk_length_seconds > total_duration_seconds:
                duration_current_chunk = total_duration_seconds - start_time_seconds
                if duration_current_chunk <= 0: # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ãŒæ—¢ã«çµ‚ã‚ã£ã¦ã„ã‚‹å ´åˆ
                    break

            chunk_file_path = os.path.join(output_dir, f"chunk_{i:04d}.mp3")

            # ffmpegã‚³ãƒãƒ³ãƒ‰:
            # -i <å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«>
            # -ss <é–‹å§‹æ™‚åˆ»> (ç§’ã¾ãŸã¯hh:mm:sså½¢å¼)
            # -t <æœŸé–“> (ç§’ã¾ãŸã¯hh:mm:sså½¢å¼)
            # -c:a copy: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã›ãšã«ã‚³ãƒ”ãƒ¼ (æœ€é€Ÿ)
            # -map_chapters -1: ãƒãƒ£ãƒ—ã‚¿ãƒ¼ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ãªã„ (ä¸è¦ãªå‡¦ç†ã‚’é¿ã‘ã‚‹)
            # -y: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã
            ffmpeg_command = [
                'ffmpeg',
                '-i', audio_file_path,
                '-ss', str(start_time_seconds),
                '-t', str(duration_current_chunk),
                '-c:a', 'copy', # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆå†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãªã„ï¼‰
                '-map_chapters', '-1', # å¿…è¦ã§ã‚ã‚Œã°ãƒãƒ£ãƒ—ã‚¿ãƒ¼ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ãªã„
                '-y', # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸Šæ›¸ãã‚’è¨±å¯
                chunk_file_path
            ]

            try:
                print(f"    ffmpeg ã§ãƒãƒ£ãƒ³ã‚¯ {i} ã‚’ä½œæˆä¸­: {start_time_seconds}s - {start_time_seconds + duration_current_chunk}s")
                subprocess.run(ffmpeg_command, check=True, capture_output=True) # æ¨™æº–å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦ãƒ­ã‚°ã‚’æŠ‘åˆ¶
                chunks.append({"index": i, "path": chunk_file_path})
            except subprocess.CalledProcessError as e:
                error_output = e.stderr.decode('utf-8') if e.stderr else "(ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ãªã—)"
                print(f"è­¦å‘Š: ffmpeg ã§ãƒãƒ£ãƒ³ã‚¯ {i} ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"    ã‚³ãƒãƒ³ãƒ‰: {' '.join(ffmpeg_command)}")
                print(f"    ã‚¨ãƒ©ãƒ¼å‡ºåŠ›:\n{error_output}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒãƒ£ãƒ³ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
            except FileNotFoundError:
                print(f"ã‚¨ãƒ©ãƒ¼: ffmpeg å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚PATHãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                raise # ffmpegãŒãªã„å ´åˆã¯è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å†raise

        return chunks

    def _transcribe_audio_chunk_parallel(self, chunk_info):
        """
        å˜ä¸€ã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’Whisper APIã«é€ä¿¡ã—ã€æ–‡å­—èµ·ã“ã—çµæœã‚’è¿”ã™ã€‚
        ä¸¦è¡Œå‡¦ç†ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã€‚
        """
        chunk_index = chunk_info["index"]
        chunk_path = chunk_info["path"]

        print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã®æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™ ({os.path.basename(chunk_path)})...")

        try:
            if openai_client is None:
                return {"index": chunk_index, "text": "", "error": "OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ (Whisper APIã®åˆ¶é™25MB)
            file_size_mb = os.path.getsize(chunk_path) / (1024 * 1024)
            if file_size_mb > 25:
                # ã“ã®ã‚±ãƒ¼ã‚¹ã¯ffmpegã®c:a copyã§ã¯ç™ºç”Ÿã—ã«ãã„ãŒã€å¿µã®ãŸã‚
                print(f"    è­¦å‘Š: ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBã‚’è¶…ãˆã¦ã„ã¾ã™ ({file_size_mb:.2f}MB)ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return {"index": chunk_index, "text": "", "error": f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ25MBã‚’è¶…é ({file_size_mb:.2f}MB)"}


            with open(chunk_path, "rb") as audio_file:
                transcript = openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ja"
                )
            print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
            return {"index": chunk_index, "text": transcript.text}
        except openai.APIError as e:
            print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã§OpenAI APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return {"index": chunk_index, "text": "", "error": f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e.code} - {e.message}"}
        except Exception as e:
            print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_index} ã®æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            return {"index": chunk_index, "text": "", "error": str(e)}
        

class AnswerProcessingAPI(APIView):
    """
    API to receive a student's answer (JPEG/PDF) directly in the request body,
    process it for corrections, identify habits, and suggest references using OpenAI GPT-4o Vision.
    The input PDF/JPEG is assumed to contain both the problem statement and the student's answer.
    """

    def post(self, request, *args, **kwargs):
        # request.FILES ã¯ä½¿ç”¨ã—ãªã„ãŸã‚ã€request.body ã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        uploaded_file_data = request.body
        content_type = request.META.get('HTTP_CONTENT_TYPE') or request.META.get('CONTENT_TYPE')

        if not uploaded_file_data:
            print("ã‚¨ãƒ©ãƒ¼: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return Response({"error": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}, status=status.HTTP_400_BAD_REQUEST)
        
        file_extension = ''
        original_filename = 'uploaded_file' # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«å
        
        # Content-Type ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¨æ¸¬
        if content_type:
            if 'application/pdf' in content_type:
                file_extension = '.pdf'
                original_filename = 'answer.pdf'
            elif 'image/jpeg' in content_type or 'image/jpg' in content_type:
                file_extension = '.jpeg'
                original_filename = 'answer.jpeg'
            elif 'image/png' in content_type:
                file_extension = '.png'
                original_filename = 'answer.png'
            else:
                print(f"ã‚¨ãƒ©ãƒ¼: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„Content-Typeã§ã™: {content_type}ã€‚è¨±å¯ã•ã‚Œã‚‹å½¢å¼ã¯JPEG, PNG, PDFã§ã™ã€‚")
                return Response({"error": "ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã¯JPEG, PNG, PDFã®ã¿ã§ã™ã€‚"}, status=status.HTTP_400_BAD_REQUEST)
        else:
            print("ã‚¨ãƒ©ãƒ¼: Content-Typeãƒ˜ãƒƒãƒ€ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’åˆ¤æ–­ã§ãã¾ã›ã‚“ã€‚")
            return Response({"error": "Content-Typeãƒ˜ãƒƒãƒ€ãƒ¼ãŒå¿…é ˆã§ã™ï¼ˆä¾‹: application/pdf, image/jpeg, image/pngï¼‰ã€‚"}, status=status.HTTP_400_BAD_REQUEST)

        temp_dir = None
        temp_filepath = None
        processed_image_path = None
        extracted_text_from_ocr = "" 

        try:
            temp_dir = tempfile.mkdtemp(dir=settings.MEDIA_ROOT)
            print(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {temp_dir}")

            # å–å¾—ã—ãŸãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            temp_filepath = os.path.join(temp_dir, original_filename)
            with open(temp_filepath, 'wb') as destination: # 'wb+'ã§ã¯ãªã'wb'ã§ååˆ†
                destination.write(uploaded_file_data)
            print(f"è§£ç­”ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜ã—ã¾ã—ãŸ: {temp_filepath}")

            if file_extension == '.pdf':
                print("PDFã‹ã‚‰ã®ç”»åƒæŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™ (PyMuPDFã‚’ä½¿ç”¨)ã€‚")
                try:
                    doc = fitz.open(temp_filepath)
                    if not doc.page_count:
                        print("ã‚¨ãƒ©ãƒ¼: PDFã«ãƒšãƒ¼ã‚¸ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                        return Response({"error": "PDFã«ãƒšãƒ¼ã‚¸ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", "detail": "Empty PDF document."}, status=status.HTTP_400_BAD_REQUEST)

                    page = doc.load_page(0)
                    
                    zoom = 300 / 72 
                    mat = fitz.Matrix(zoom, zoom)
                    
                    pix = page.get_pixmap(matrix=mat)
                    
                    base_name = os.path.splitext(original_filename)[0]
                    processed_image_filename = os.path.join(temp_dir, f'{base_name}_page_0001.png')
                    
                    pix.save(processed_image_filename)
                    processed_image_path = processed_image_filename
                    doc.close()
                    print(f"PyMuPDFã§PDFã‹ã‚‰ç”»åƒã‚’æŠ½å‡ºã—ã¾ã—ãŸ: {processed_image_path}")
                    
                except fitz.EmptyFileError:
                    print(f"PyMuPDFã‚¨ãƒ©ãƒ¼: ç©ºã®PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {temp_filepath}")
                    return Response({"error": "ç©ºã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚", "detail": "Empty PDF document."}, status=status.HTTP_400_BAD_REQUEST)
                except fitz.PasswordError:
                    print(f"PyMuPDFã‚¨ãƒ©ãƒ¼: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ä¿è­·ã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã§ã™: {temp_filepath}")
                    return Response({"error": "ä¿è­·ã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚", "detail": "Password protected PDF."}, status=status.HTTP_400_BAD_REQUEST)
                except Exception as e:
                    print(f"PyMuPDFã§ã®PDFç”»åƒæŠ½å‡ºä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                    return Response({"error": "PDFã‹ã‚‰ã®ç”»åƒæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ (PyMuPDF)ã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            else:
                processed_image_path = temp_filepath

            # Tesseract OCR ã‚’å®Ÿè¡Œ (LLMã®å‚è€ƒç”¨ã®ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ)
            if processed_image_path and os.path.exists(processed_image_path):
                print("Tesseract OCRã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™ã€‚")
                try:
                    image_for_ocr = Image.open(processed_image_path)
                    extracted_text_from_ocr = pytesseract.image_to_string(image_for_ocr, lang='jpn+eng')
                    print("Tesseract OCRã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                except pytesseract.pytesseract.TesseractNotFoundError:
                    print("ã‚¨ãƒ©ãƒ¼: Tesseract OCRãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ã‹ã€PATHãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                except Exception as e:
                    print(f"Tesseract OCRã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            else:
                print("è­¦å‘Š: å‡¦ç†ã™ã¹ãç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Tesseract OCRã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

            # 3. OpenAI GPT-4o Vision ã§è§£ç­”å†…å®¹ã‚’è§£æã€æ‰‹ç›´ã—ã€ç™–ã®ç‰¹å®š
            print("ã‚¹ãƒ†ãƒƒãƒ—3: OpenAI GPT-4o Vision ã§è§£ç­”å†…å®¹ã®è§£æã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            overall_user_habit_analysis = "è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

            if openai_client is None:
                print("ã‚¨ãƒ©ãƒ¼: OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return Response({"error": "OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            try:
                with open(processed_image_path, "rb") as image_file:
                    base64_image = base64.b64encode(image_file.read()).decode('utf-8')

                prompt_text = f"""
ä»¥ä¸‹ã®ç”»åƒã«ã¯ã€**å•é¡Œæ–‡ã¨ç”Ÿå¾’ã®æ‰‹æ›¸ãè§£ç­”ã®ä¸¡æ–¹**ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
ç”»åƒã‚’æ­£ç¢ºã«èª­ã¿å–ã‚Šã€**å•é¡Œæ–‡ã®å†…å®¹ã‚’å®Œå…¨ã«ç†è§£ã—ãŸä¸Šã§**ã€ãã‚Œã«å¯¾ã™ã‚‹ç”Ÿå¾’ã®è§£ç­”ã®**å…¨ä½“ã®è§£ç­”æ–¹é‡ã€è¨ˆç®—éç¨‹ã€è«–ç†å±•é–‹**ã«ã¤ã„ã¦ä¿®æ­£ç‚¹ã‚„æ”¹å–„ç‚¹ã‚’**ç·åˆçš„ã«**æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€ã“ã®è§£ç­”ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹**è§£ç­”è€…ã®å…¸å‹çš„ãªå­¦ç¿’ã®ç™–ã‚„æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³**ã‚’è©³ç´°ã«åˆ†æã—ã€ä»Šå¾Œã®å­¦ç¿’ã«å½¹ç«‹ã¤å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
æ•°å¼ã‚„å›³å½¢ã«ã¤ã„ã¦ã‚‚æ­£ç¢ºã«èª­ã¿å–ã‚Šã€**LaTeXå½¢å¼**ï¼ˆã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã¯`$`ã§å›²ã‚€ã€ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤æ•°å¼ã¯`$$`ã§å›²ã‚€ï¼‰ã§è¡¨ç¾ã—ã¦ä¿®æ­£æ¡ˆã«å«ã‚ã¦ãã ã•ã„ã€‚

---
**ã€å‚è€ƒæƒ…å ±ï¼šTesseract OCRã§æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€‘**
ã“ã®æƒ…å ±ã¯ã€ç”»åƒå†…ã®æ‰‹æ›¸ãæ–‡å­—ã‚„è¤‡é›‘ãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãŒéå¸¸ã«èª­ã¿ã«ãã„å ´åˆã®è£œåŠ©ã¨ã—ã¦åˆ©ç”¨ã—ã¦ãã ã•ã„ã€‚
{extracted_text_from_ocr if extracted_text_from_ocr else "ï¼ˆOCRã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯æŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰"}

---
ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

## å…¨ä½“çš„ãªè§£ç­”ã®ä¿®æ­£æ¡ˆã¨æ”¹å–„ç‚¹
ï¼ˆã“ã“ã«è§£ç­”å…¨ä½“ã«ã‚ãŸã‚‹ä¿®æ­£ç‚¹ã€æ­£ã—ã„æ–¹é‡ã€æ”¹å–„ã®ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è©³ç´°ã«è¨˜è¿°ã€‚æ•°å¼ã¯LaTeXå½¢å¼ã§è¡¨ç¾ï¼‰

## è§£ç­”è€…ã®å­¦ç¿’ã®ç™–ã¨ä»Šå¾Œã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
ï¼ˆã“ã“ã«è§£ç­”ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ç”Ÿå¾’ã®å…¸å‹çš„ãªèª¤ã‚Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å­¦ç¿’ã®ç™–ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã€æ”¹å–„ç­–ã‚‚æç¤ºï¼‰
"""

                messages = [
                    {"role": "system", "content": "ã‚ãªãŸã¯æ•°å­¦ã‚„ç‰©ç†ã®å®¶åº­æ•™å¸«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æä¾›ã•ã‚ŒãŸç”»åƒï¼ˆå•é¡Œæ–‡ã¨ç”Ÿå¾’ã®è§£ç­”ãŒä¸€ä½“ã¨ãªã£ã¦ã„ã‚‹ï¼‰ã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã€å…¨ä½“çš„ãªä¿®æ­£æ¡ˆã¨å­¦ç¿’ã®ç™–ã‚’ç‰¹å®šã—ã€åŠ©è¨€ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚æ•°å¼ã¯LaTeXå½¢å¼ã§æ­£ç¢ºã«è¡¨ç¾ã—ã¾ã™ã€‚"}, 
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt_text},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                        ]
                    }
                ]
                
                print("OpenAI GPT-4o Vision APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
                response_gpt4_vision = openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    max_tokens=2500,
                    temperature=0.5,
                )
                
                full_analysis = response_gpt4_vision.choices[0].message.content.strip()
                print("GPT-4o Visionã‹ã‚‰ã®å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚")
                
                match_correction_advice = re.search(r'## å…¨ä½“çš„ãªè§£ç­”ã®ä¿®æ­£æ¡ˆã¨æ”¹å–„ç‚¹\n([\s\S]*?)(?=## è§£ç­”è€…ã®å­¦ç¿’ã®ç™–ã¨ä»Šå¾Œã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹|\Z)', full_analysis)
                if match_correction_advice:
                    pass 
                else:
                    print("è­¦å‘Š: LLMã®å‡ºåŠ›ã‹ã‚‰ã€Œå…¨ä½“çš„ãªè§£ç­”ã®ä¿®æ­£æ¡ˆã¨æ”¹å–„ç‚¹ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

                match_habit_analysis = re.search(r'## è§£ç­”è€…ã®å­¦ç¿’ã®ç™–ã¨ä»Šå¾Œã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹\n([\s\S]*)', full_analysis)
                if match_habit_analysis:
                    overall_user_habit_analysis = match_habit_analysis.group(1).strip()
                else:
                    print("è­¦å‘Š: LLMã®å‡ºåŠ›ã‹ã‚‰ã€Œè§£ç­”è€…ã®å­¦ç¿’ã®ç™–ã¨ä»Šå¾Œã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    overall_user_habit_analysis = "ã€Œè§£ç­”è€…ã®å­¦ç¿’ã®ç™–ã¨ä»Šå¾Œã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã€ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                        
                print("è§£ç­”ã®ç·åˆçš„ãªè§£æå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

            except openai.RateLimitError as e:
                print(f"ã‚¨ãƒ©ãƒ¼: OpenAI APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¾ãŸã¯ã‚¯ã‚©ãƒ¼ã‚¿è¶…éã€‚è©³ç´°: {e.message}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({
                    "error": "OpenAI APIã®ä½¿ç”¨ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚", 
                    "detail": f"OpenAIã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {e.message}"
                }, status=status.HTTP_429_TOO_MANY_REQUESTS)
            except openai.APIStatusError as e:
                print(f"ã‚¨ãƒ©ãƒ¼: OpenAI APIã‹ã‚‰HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼ãŒè¿”ã•ã‚Œã¾ã—ãŸ: {e.status_code} - {e.response}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({
                    "error": "OpenAI APIã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    "detail": f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {e.status_code}, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {e.response}"
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            except openai.APIConnectionError as e:
                print(f"ã‚¨ãƒ©ãƒ¼: OpenAI APIã¸ã®æ¥ç¶šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({
                    "error": "OpenAI APIã¸ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                    "detail": str(e)
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼: è§£ç­”è§£æä¸­ã«äºˆæœŸã›ã¬OpenAI APIé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
                return Response({"error": "è§£ç­”ã®è§£æä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


            return Response({
                "overall_user_habit_analysis": overall_user_habit_analysis,
            }, status=status.HTTP_200_OK)

        except Exception as e:
            traceback_str = traceback.format_exc()
            print(f"APIå‡¦ç†ã®åˆæœŸæ®µéšã§äºˆæœŸã›ã¬ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback_str}")
            return Response({"error": "å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", "detail": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
        finally:
            if temp_dir and os.path.exists(temp_dir):
                print(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã™: {temp_dir}")
                shutil.rmtree(temp_dir)